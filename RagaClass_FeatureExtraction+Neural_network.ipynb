{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g4EmfUAjDuhc"
   },
   "source": [
    "#Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MdJFDmw1CIPM"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "df4ip8iRBpiw"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "raga\n",
       "Purvikalyani         240\n",
       "abhogi               240\n",
       "ananda bhairavi      240\n",
       "atana                200\n",
       "begada               240\n",
       "behag                240\n",
       "bhairavi             240\n",
       "bilahari             210\n",
       "darbar               150\n",
       "hamsadhvani          240\n",
       "hindolam             250\n",
       "jaganmohini          150\n",
       "jaunpuri             140\n",
       "mayamalava gaula     150\n",
       "ragamalika           150\n",
       "shanmukhapriya       160\n",
       "varali               150\n",
       "vasanta              150\n",
       "yadukula kambhoji    150\n",
       "yamuna kalyani       150\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=pd.read_csv('dataset-big.csv')\n",
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)\n",
    "#Encoding the Labels\n",
    "raga_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(raga_list)\n",
    "#Scaling the Feature columns\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "#Dividing data into training and Testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "data.groupby(\"raga\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fR6Bcn1hHQtq",
    "outputId": "429635f9-9c92-4899-c00f-c21efa5fd0d1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 ... 13 13 13]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JMw-4t4rCM7x"
   },
   "outputs": [],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y8QM8Em3CiLs"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'eta': 0.04, \n",
    "    'max_depth': 3,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 20,                  #Change when number of raga changes\n",
    "    'base_score': 0.5,\n",
    "    'booster':'gbtree',\n",
    "    'colsample_bylevel':1,\n",
    "    'colsample_bynode':1, \n",
    "    'colsample_bytree':0.7, \n",
    "    'gamma':0.0,\n",
    "    'learning_rate':0.1, \n",
    "    'min_child_weight':1, \n",
    "    'n_estimators':100, \n",
    "    'n_jobs':1,\n",
    "} \n",
    "\n",
    "steps = 20  # The number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NNv7MHskCkyS"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sypher/.local/lib/python3.10/site-packages/xgboost/core.py:160: UserWarning: [14:32:59] WARNING: /workspace/src/learner.cc:742: \n",
      "Parameters: { \"n_estimators\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "model = xgb.train(param, D_train, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "MYQf8zCNCyKQ",
    "outputId": "165b96cb-867a-468f-e16d-93d73f43dc08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9818544138507856\n",
      "Recall = 0.9814230943160963\n",
      "Accuracy = 0.9856770833333334\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "preds = model.predict(D_test)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZpcCenxifwyE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Raga for this song is : abhogi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19496/3154072433.py:16: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataset = dataset._append(dataseries, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname=\"carnatic/Kanakadurga Venkatesh at Arkay by Kanakadurga Venkatesh/Lokavana Chatura/Lokavana Chatura.mp3.mp3\"\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rms(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset._append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "example=xgb.DMatrix(example)\n",
    "preds = model.predict(example)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(best_preds)\n",
    "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g2w6XaFaDlU4"
   },
   "source": [
    "# Logistic Regression + Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "08DrpBUkDpPn",
    "outputId": "f5584152-4919-43c3-df95-d7366e3e3fb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegress classifier on training set: 0.665\n",
      "Accuracy of LogisticRegress classifier on test set: 0.542\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "print('Accuracy of LogisticRegress classifier on training set: {:.3f}'.format(logreg.score(X_train, Y_train)))\n",
    "print('Accuracy of LogisticRegress classifier on test set: {:.3f}'.format(logreg.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "40vHTmbqF4ob",
    "outputId": "6914e743-0f00-46c2-f273-5ae5ed7225ed"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19496/3165848628.py:3: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  x, sr = librosa.load(songname, mono=True, duration=30)\n",
      "/home/sypher/.local/lib/python3.10/site-packages/librosa/core/audio.py:183: FutureWarning: librosa.core.audio.__audioread_load\n",
      "\tDeprecated as of librosa version 0.10.0.\n",
      "\tIt will be removed in librosa version 1.0.\n",
      "  y, sr_native = __audioread_load(path, offset, duration, dtype)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/hindolam.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLibsndfileError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:175\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 175\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__soundfile_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m sf\u001b[38;5;241m.\u001b[39mSoundFileRuntimeError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;66;03m# If soundfile failed, try audioread instead\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:208\u001b[0m, in \u001b[0;36m__soundfile_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;66;03m# Otherwise, create the soundfile object\u001b[39;00m\n\u001b[0;32m--> 208\u001b[0m     context \u001b[38;5;241m=\u001b[39m \u001b[43msf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSoundFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context \u001b[38;5;28;01mas\u001b[39;00m sf_desc:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/soundfile.py:658\u001b[0m, in \u001b[0;36mSoundFile.__init__\u001b[0;34m(self, file, mode, samplerate, channels, subtype, endian, format, closefd)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m _create_info_struct(file, mode, samplerate, channels,\n\u001b[1;32m    657\u001b[0m                                  \u001b[38;5;28mformat\u001b[39m, subtype, endian)\n\u001b[0;32m--> 658\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode_int\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosefd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(mode)\u001b[38;5;241m.\u001b[39missuperset(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseekable():\n\u001b[1;32m    660\u001b[0m     \u001b[38;5;66;03m# Move write position to 0 (like in Python file objects)\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/soundfile.py:1216\u001b[0m, in \u001b[0;36mSoundFile._open\u001b[0;34m(self, file, mode_int, closefd)\u001b[0m\n\u001b[1;32m   1215\u001b[0m     err \u001b[38;5;241m=\u001b[39m _snd\u001b[38;5;241m.\u001b[39msf_error(file_ptr)\n\u001b[0;32m-> 1216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LibsndfileError(err, prefix\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError opening \u001b[39m\u001b[38;5;132;01m{0!r}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname))\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode_int \u001b[38;5;241m==\u001b[39m _snd\u001b[38;5;241m.\u001b[39mSFM_WRITE:\n\u001b[1;32m   1218\u001b[0m     \u001b[38;5;66;03m# Due to a bug in libsndfile version <= 1.0.25, frames != 0\u001b[39;00m\n\u001b[1;32m   1219\u001b[0m     \u001b[38;5;66;03m# when opening a named pipe in SFM_WRITE mode.\u001b[39;00m\n\u001b[1;32m   1220\u001b[0m     \u001b[38;5;66;03m# See http://github.com/erikd/libsndfile/issues/77.\u001b[39;00m\n",
      "\u001b[0;31mLibsndfileError\u001b[0m: Error opening '/content/hindolam.mp3': System error.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mlibrosa\u001b[39;00m\n\u001b[1;32m      2\u001b[0m songname\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/content/hindolam.mp3\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 3\u001b[0m x, sr \u001b[38;5;241m=\u001b[39m \u001b[43mlibrosa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43msongname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmono\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m rmse \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mrmse(y\u001b[38;5;241m=\u001b[39mx)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m chroma_stft \u001b[38;5;241m=\u001b[39m librosa\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mchroma_stft(y\u001b[38;5;241m=\u001b[39mx, sr\u001b[38;5;241m=\u001b[39msr)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:183\u001b[0m, in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path, (\u001b[38;5;28mstr\u001b[39m, pathlib\u001b[38;5;241m.\u001b[39mPurePath)):\n\u001b[1;32m    180\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    181\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPySoundFile failed. Trying audioread instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m    182\u001b[0m     )\n\u001b[0;32m--> 183\u001b[0m     y, sr_native \u001b[38;5;241m=\u001b[39m \u001b[43m__audioread_load\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moffset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mduration\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/decorator.py:232\u001b[0m, in \u001b[0;36mdecorate.<locals>.fun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kwsyntax:\n\u001b[1;32m    231\u001b[0m     args, kw \u001b[38;5;241m=\u001b[39m fix(args, kw, sig)\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcaller\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mextras\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/util/decorators.py:59\u001b[0m, in \u001b[0;36mdeprecated.<locals>.__wrapper\u001b[0;34m(func, *args, **kwargs)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Warn the user, and then proceed.\"\"\"\u001b[39;00m\n\u001b[1;32m     51\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m     52\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mDeprecated as of librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124mIt will be removed in librosa version \u001b[39m\u001b[38;5;132;01m{:s}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Would be 2, but the decorator adds a level\u001b[39;00m\n\u001b[1;32m     58\u001b[0m )\n\u001b[0;32m---> 59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/librosa/core/audio.py:239\u001b[0m, in \u001b[0;36m__audioread_load\u001b[0;34m(path, offset, duration, dtype)\u001b[0m\n\u001b[1;32m    236\u001b[0m     reader \u001b[38;5;241m=\u001b[39m path\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;66;03m# If the input was not an audioread object, try to open it\u001b[39;00m\n\u001b[0;32m--> 239\u001b[0m     reader \u001b[38;5;241m=\u001b[39m \u001b[43maudioread\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maudio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m reader \u001b[38;5;28;01mas\u001b[39;00m input_file:\n\u001b[1;32m    242\u001b[0m     sr_native \u001b[38;5;241m=\u001b[39m input_file\u001b[38;5;241m.\u001b[39msamplerate\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/audioread/__init__.py:127\u001b[0m, in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m BackendClass \u001b[38;5;129;01min\u001b[39;00m backends:\n\u001b[1;32m    126\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 127\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBackendClass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DecodeError:\n\u001b[1;32m    129\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/audioread/rawread.py:59\u001b[0m, in \u001b[0;36mRawAudioFile.__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename):\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_file \u001b[38;5;241m=\u001b[39m aifc\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fh)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/hindolam.mp3'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname='/content/hindolam.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rmse(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset.append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "preds = logreg.predict(example)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(preds)\n",
    "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wwj3OAn0EoBH"
   },
   "source": [
    "# Naive Bayes + Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "YM1kTBRcEq7Q",
    "outputId": "4b22950c-651e-4bb0-a04f-0c5eaa5dd7c0"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'abhogi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#Scaling the Feature columns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[0;32m----> 6\u001b[0m X \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraga_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#Dividing data into training and Testing set\u001b[39;00m\n\u001b[1;32m      8\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:1021\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1021\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1023\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'abhogi'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "y = encoder.fit_transform(raga_list)\n",
    "#Scaling the Feature columns\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:,:-1], dtype = float))\n",
    "#Dividing data into training and Testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "modelNB = MultinomialNB()   \n",
    "modelNB.fit(X_train, Y_train)\n",
    "print('Accuracy of NaiveBayes classifier on training set: {:.2f}'.format(modelNB.score(X_train, Y_train)))\n",
    "print('Accuracy of NaiveBayes classifier on test set: {:.2f}'.format(modelNB.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "3heLVQN8Ia6j",
    "outputId": "2f9e3f04-32a3-49ff-c0c7-36de9f82e41f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Raga for this song is : abhogi\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname='carnatic/Kanakadurga Venkatesh at Arkay by Kanakadurga Venkatesh/Lokavana Chatura/Lokavana Chatura.mp3.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rmse(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset.append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "preds = modelNB.predict(example)\n",
    "#best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(preds)\n",
    "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Purvikalyani', 0), ('abhogi', 1), ('ananda bhairavi', 2), ('atana', 3), ('begada', 4), ('behag', 5), ('bhairavi', 6), ('bilahari', 7), ('darbar', 8), ('hamsadhvani', 9), ('hindolam', 10), ('jaganmohini', 11), ('jaunpuri', 12), ('mayamalava gaula', 13), ('ragamalika', 14), ('shanmukhapriya', 15), ('varali', 16), ('vasanta', 17), ('yadukula kambhoji', 18), ('yamuna kalyani', 19)]\n"
     ]
    }
   ],
   "source": [
    "print(raganame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ij1RE5crJ1dA"
   },
   "source": [
    "# Random Forest + Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yO_PhrWEJ5PV"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "d1wvSWEbKGrC",
    "outputId": "a1d557fe-d890-451f-d9b1-14fda7ef1090"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest classifier on training set: 1.00\n",
      "Accuracy of RandomForest classifier on training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_train, Y_train)))\n",
    "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "p3HW_QyMKf25",
    "outputId": "f05e6964-eece-4f3d-cb8b-1cbd07cd7d1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[1.]\n",
      "Raga for this song is : Purvikalyani\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_19809/621777137.py:15: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  dataset = dataset._append(dataseries, ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "songname='carnatic/Kanakadurga Venkatesh at Arkay by Kanakadurga Venkatesh/Lokavana Chatura/Lokavana Chatura.mp3.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rms(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset._append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "preds = rf.predict(example)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(best_preds)\n",
    "print(preds)\n",
    "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "svPnSufGTfeS"
   },
   "source": [
    "#Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-SNS8rlsTfeT"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "InyDbmqVTfeW"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('dataset-nosource.csv')\n",
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)\n",
    "#Encoding the Labels\n",
    "raga_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(raga_list)\n",
    "#Scaling the Feature columns\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "#Dividing data into training and Testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wyDAG_hZTfeY",
    "outputId": "1948038b-63ba-4758-b57c-e02548a4aa1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 5 5 5]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oY5sQhmpTfeb"
   },
   "source": [
    "#XGBoost + Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "qeILMpQ5Tfeb",
    "outputId": "90f98fc9-5354-45e4-f65c-dea5c90b056e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CA2uQqf3Tfed"
   },
   "outputs": [],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sW_wiYPkTfef"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'eta': 0.04, \n",
    "    'max_depth': 3,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 10,                  #Change when number of raga changes\n",
    "    'base_score': 0.5,\n",
    "    'booster':'gbtree',\n",
    "    'colsample_bylevel':1,\n",
    "    'colsample_bynode':1, \n",
    "    'colsample_bytree':0.7, \n",
    "    'gamma':0.0,\n",
    "    'learning_rate':0.1, \n",
    "    'min_child_weight':1, \n",
    "    'n_estimators':100, \n",
    "    'n_jobs':1,\n",
    "} \n",
    "\n",
    "steps = 20  # The number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h_FvGfdfTfei"
   },
   "outputs": [],
   "source": [
    "model = xgb.train(param, D_train, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "Wj66qxz_Tfek",
    "outputId": "8a62cc6a-33d9-4caf-9f58-4719cb1c6446"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9962962962962962\n",
      "Recall = 0.9975609756097562\n",
      "Accuracy = 0.9966666666666667\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "preds = model.predict(D_test)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "gonFKyFwTfem",
    "outputId": "33899373-1953-47ab-93c8-c612094420fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Raga for this song is : abhogi\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname='/content/abogi.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rmse(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset.append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "example=xgb.DMatrix(example)\n",
    "preds = model.predict(example)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(best_preds)\n",
    "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Is3kzHzmTfeo"
   },
   "source": [
    "#Logistic Regression + Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "iPYv2OfOTfep",
    "outputId": "6f3e1a64-738d-40fa-8aff-94f9a172ab27"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegress classifier on training set: 0.837\n",
      "Accuracy of LogisticRegress classifier on test set: 0.790\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "print('Accuracy of LogisticRegress classifier on training set: {:.3f}'.format(logreg.score(X_train, Y_train)))\n",
    "print('Accuracy of LogisticRegress classifier on test set: {:.3f}'.format(logreg.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "5bjESCZ-Tfer",
    "outputId": "6914e743-0f00-46c2-f273-5ae5ed7225ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Raga for this song is : abhogi\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname='/content/hindolam.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rmse(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset.append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "preds = logreg.predict(example)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(preds)\n",
    "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UUGlPJvRTfet"
   },
   "source": [
    "#Naive Bayes + Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Wtbo4QKGTfet",
    "outputId": "6b9a01aa-6901-4194-c90a-6409269e5bd4"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'abhogi'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m#Scaling the Feature columns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[0;32m----> 4\u001b[0m X \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mraga_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#Dividing data into training and Testing set\u001b[39;00m\n\u001b[1;32m      6\u001b[0m X_train, X_test, Y_train, Y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/series.py:1021\u001b[0m, in \u001b[0;36mSeries.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m    974\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    975\u001b[0m \u001b[38;5;124;03mReturn the values as a NumPy array.\u001b[39;00m\n\u001b[1;32m    976\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m      dtype='datetime64[ns]')\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m-> 1021\u001b[0m arr \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m using_copy_on_write() \u001b[38;5;129;01mand\u001b[39;00m astype_is_view(values\u001b[38;5;241m.\u001b[39mdtype, arr\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[1;32m   1023\u001b[0m     arr \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mview()\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'abhogi'"
     ]
    }
   ],
   "source": [
    "y = encoder.fit_transform(raga_list)\n",
    "#Scaling the Feature columns\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(np.array(raga_list, dtype = float))\n",
    "#Dividing data into training and Testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "modelNB = MultinomialNB()   \n",
    "modelNB.fit(X_train, Y_train)\n",
    "print('Accuracy of NaiveBayes classifier on training set: {:.2f}'.format(modelNB.score(X_train, Y_train)))\n",
    "print('Accuracy of NaiveBayes classifier on test set: {:.2f}'.format(modelNB.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Sywfv0nUTfew",
    "outputId": "2f9e3f04-32a3-49ff-c0c7-36de9f82e41f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Raga for this song is : abhogi\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname='/content/abogi.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rmse(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset.append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "preds = modelNB.predict(example)\n",
    "#best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(preds)\n",
    "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SqVBIudiTfex"
   },
   "source": [
    "#Random Forest + Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbDi02oOTfey"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "keEuaL7WTfez",
    "outputId": "0baec4ff-e5f4-42d6-a16c-debb7fbeb9cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest classifier on training set: 1.00\n",
      "Accuracy of RandomForest classifier on training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_train, Y_train)))\n",
    "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "l-Hs225dTfe2",
    "outputId": "f05e6964-eece-4f3d-cb8b-1cbd07cd7d1f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dc7690f9f467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msongname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/hindolam.mp3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchroma_stft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/hindolam.mp3'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname='/content/hindolam.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rmse(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset.append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "preds = rf.predict(example)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(best_preds)\n",
    "print(preds)\n",
    "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "A8Nmy6t_WVgB"
   },
   "source": [
    "# 20 Ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aMbCPvKJWtOE"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ghvazcc2Wxh6"
   },
   "source": [
    "#Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-yepVTYmWxiB"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import xgboost as xgb\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3RlfQaSkWxiF"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv('dataset-big.csv')\n",
    "# Dropping unneccesary columns\n",
    "data = data.drop(['filename'],axis=1)\n",
    "#Encoding the Labels\n",
    "raga_list = data.iloc[:, -1]\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(raga_list)\n",
    "#Scaling the Feature columns\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "#Dividing data into training and Testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "P1WqqKcXWxiH",
    "outputId": "8a56b04a-ffe3-4665-e361-fbcfbfb59540"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  1  1 ... 13 13 13]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TorQgJ3iWxiL"
   },
   "source": [
    "#XGBoost + Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "PIfgIfugWxiL",
    "outputId": "96d9006f-d56a-47df-a8ef-8a70f5c57e68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /usr/local/lib/python3.6/dist-packages (0.90)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.4.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from xgboost) (1.18.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aYwmOu3GWxiO"
   },
   "outputs": [],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=Y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YxSQK68BWxiP"
   },
   "outputs": [],
   "source": [
    "param = {\n",
    "    'eta': 0.04, \n",
    "    'max_depth': 3,  \n",
    "    'objective': 'multi:softprob',  \n",
    "    'num_class': 20,                  #Change when number of raga changes\n",
    "    'base_score': 0.5,\n",
    "    'booster':'gbtree',\n",
    "    'colsample_bylevel':1,\n",
    "    'colsample_bynode':1, \n",
    "    'colsample_bytree':0.7, \n",
    "    'gamma':0.0,\n",
    "    'learning_rate':0.1, \n",
    "    'min_child_weight':1, \n",
    "    'n_estimators':100, \n",
    "    'n_jobs':1,\n",
    "} \n",
    "\n",
    "steps = 20  # The number of training iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CoetgfL7WxiS"
   },
   "outputs": [],
   "source": [
    "model = xgb.train(param, D_train, steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 67
    },
    "colab_type": "code",
    "id": "6HC1c6mdWxiV",
    "outputId": "2dc6a235-f9a5-4f4c-a79d-ccb9b4f1a9b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 0.9959444444444443\n",
      "Recall = 0.9959565412186379\n",
      "Accuracy = 0.99609375\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, accuracy_score\n",
    "\n",
    "preds = model.predict(D_test)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "print(\"Precision = {}\".format(precision_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Recall = {}\".format(recall_score(Y_test, best_preds, average='macro')))\n",
    "print(\"Accuracy = {}\".format(accuracy_score(Y_test, best_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "FXkGC1ErWxiX",
    "outputId": "33899373-1953-47ab-93c8-c612094420fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Raga for this song is : abhogi\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname='/content/abogi.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rmse(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset.append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "example=xgb.DMatrix(example)\n",
    "preds = model.predict(example)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(best_preds)\n",
    "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "npoBqi-ZWxib"
   },
   "source": [
    "#Logistic Regression + Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "kMzPWI6VWxic",
    "outputId": "7c901451-77de-4841-ca99-d7a1fdb8cfe7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of LogisticRegress classifier on training set: 0.651\n",
      "Accuracy of LogisticRegress classifier on test set: 0.590\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, Y_train)\n",
    "print('Accuracy of LogisticRegress classifier on training set: {:.3f}'.format(logreg.score(X_train, Y_train)))\n",
    "print('Accuracy of LogisticRegress classifier on test set: {:.3f}'.format(logreg.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "blkmO4n4Wxif",
    "outputId": "6914e743-0f00-46c2-f273-5ae5ed7225ed"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Raga for this song is : abhogi\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname='/content/hindolam.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rmse(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset.append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "preds = logreg.predict(example)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(preds)\n",
    "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HowVqZdWxii"
   },
   "source": [
    "#Naive Bayes + Pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "o_p8xjRmWxij",
    "outputId": "50bfa9fc-033f-4364-807b-9fe691cb5cfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of NaiveBayes classifier on training set: 0.23\n",
      "Accuracy of NaiveBayes classifier on test set: 0.22\n"
     ]
    }
   ],
   "source": [
    "y = encoder.fit_transform(raga_list)\n",
    "#Scaling the Feature columns\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(np.array(data.iloc[:, :-1], dtype = float))\n",
    "#Dividing data into training and Testing set\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n",
    "modelNB = MultinomialNB()   \n",
    "modelNB.fit(X_train, Y_train)\n",
    "print('Accuracy of NaiveBayes classifier on training set: {:.2f}'.format(modelNB.score(X_train, Y_train)))\n",
    "print('Accuracy of NaiveBayes classifier on test set: {:.2f}'.format(modelNB.score(X_test, Y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "N71azDnHWxil",
    "outputId": "2f9e3f04-32a3-49ff-c0c7-36de9f82e41f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\n",
      "Raga for this song is : abhogi\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname='/content/abogi.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rmse(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset.append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "preds = modelNB.predict(example)\n",
    "#best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(preds)\n",
    "print(\"Raga for this song is : \"+raganame[preds[0]][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WLmk9paxWxip"
   },
   "source": [
    "#Random Forest + Preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FUaD6l05Wxip"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(X_train, Y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "Ux4bgU5gWxir",
    "outputId": "1d67a52e-c910-455b-989c-6f94053b701f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of RandomForest classifier on training set: 1.00\n",
      "Accuracy of RandomForest classifier on training set: 1.00\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_train, Y_train)))\n",
    "print('Accuracy of RandomForest classifier on training set: {:.2f}'.format(rf.score(X_test, Y_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "nqoLc2h9Wxiv",
    "outputId": "f05e6964-eece-4f3d-cb8b-1cbd07cd7d1f"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-dc7690f9f467>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0msongname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/hindolam.mp3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msongname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmono\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mduration\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mrmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mchroma_stft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibrosa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchroma_stft\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/librosa/core/audio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(path, sr, mono, offset, duration, dtype, res_type)\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0maudioread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maudio_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrealpath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m         \u001b[0msr_native\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamplerate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m         \u001b[0mn_channels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/__init__.py\u001b[0m in \u001b[0;36maudio_open\u001b[0;34m(path, backends)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mBackendClass\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbackends\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mBackendClass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mDecodeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/audioread/rawread.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \"\"\"\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/hindolam.mp3'"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "songname='/content/hindolam.mp3'\n",
    "x, sr = librosa.load(songname, mono=True, duration=30)\n",
    "rmse = librosa.feature.rmse(y=x)[0]\n",
    "chroma_stft = librosa.feature.chroma_stft(y=x, sr=sr)\n",
    "spec_cent = librosa.feature.spectral_centroid(y=x, sr=sr)\n",
    "spec_bw = librosa.feature.spectral_bandwidth(y=x, sr=sr)\n",
    "rolloff = librosa.feature.spectral_rolloff(y=x, sr=sr)\n",
    "zcr = librosa.feature.zero_crossing_rate(x)\n",
    "mfcc = librosa.feature.mfcc(y=x, sr=sr)\n",
    "\n",
    "data=[0,np.mean(rmse),np.mean(chroma_stft),np.mean(spec_cent),np.mean(spec_bw),np.mean(rolloff),np.mean(zcr),np.mean(mfcc[0]),np.mean(mfcc[1]),np.mean(mfcc[2]),np.mean(mfcc[3]),np.mean(mfcc[4]),np.mean(mfcc[5]),np.mean(mfcc[6]),np.mean(mfcc[7]),np.mean(mfcc[8]),np.mean(mfcc[9]),np.mean(mfcc[10]),np.mean(mfcc[11]),np.mean(mfcc[12]),np.mean(mfcc[13]),np.mean(mfcc[14]),np.mean(mfcc[15]),np.mean(mfcc[16]),np.mean(mfcc[17]),np.mean(mfcc[18]),np.mean(mfcc[19])]\n",
    "columns=['ind','rmse','chroma_stft','spec_cent','spec_bw','rolloff','zcr','mfcc0','mfcc1','mfcc2','mfcc3','mfcc4','mfcc5','mfcc6','mfcc7','mfcc8','mfcc9','mfcc10','mfcc11','mfcc12','mfcc13','mfcc14','mfcc15','mfcc16','mfcc17','mfcc18','mfcc19']\n",
    "dataset=pd.DataFrame(columns=columns)\n",
    "dataseries = pd.Series(data, index = dataset.columns)\n",
    "dataset = dataset.append(dataseries, ignore_index=True)\n",
    "\n",
    "example = scaler.transform(np.array(dataset.iloc[:, :], dtype = float))\n",
    "preds = rf.predict(example)\n",
    "best_preds = np.asarray([np.argmax(line) for line in preds])\n",
    "\n",
    "raganame=set()\n",
    "for i in range(len(raga_list)):\n",
    "  raganame.add((raga_list[i],y[i]))\n",
    "raganame=list(raganame)\n",
    "raganame.sort()\n",
    "print(best_preds)\n",
    "print(preds)\n",
    "print(\"Raga for this song is : \"+raganame[best_preds[0]][0])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of RagaClass-FeatureExtraction+Algo.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
